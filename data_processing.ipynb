{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naming convention: </br> path: xxXx </br> list: xxXx </br> dataframe: xx_xx </br> parameter: xx_xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path and file name\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files in directory\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "fileName = loadPath + '002491.SZ.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def md(data, n, val_name, f):\n",
    "    values = []\n",
    "    MD = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        values.append(row[val_name])\n",
    "        if len(values) == n:\n",
    "            del values[0]\n",
    "\n",
    "        MD.append(np.average(values))\n",
    "    colName = 'MD_'+str(n)\n",
    "    data[colName] = MD\n",
    "    fileName = savePath + f\n",
    "    data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    n = input('Day you want to calculate?')\n",
    "    n = int(n)\n",
    "    val_name = input('Value you want to calculate?')\n",
    "\n",
    "    data = pd.read_csv(fileName)\n",
    "\n",
    "    #call function to calculate n day moving average\n",
    "    md(data, n, val_name, f)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [?] 10-day moving deviation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def md(data, n, val_name, f):\n",
    "    values = []\n",
    "    MD = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        values.append(row[val_name])\n",
    "        if len(values) == n:\n",
    "            del values[0]\n",
    "\n",
    "        MD.append(np.std(values))\n",
    "    colName = 'MD_'+str(n)\n",
    "    data[colName] = MD\n",
    "    fileName = savePath + f\n",
    "    data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    n = input('Day you want to calculate?')\n",
    "    n = int(n)\n",
    "    val_name = input('Value you want to calculate?')\n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        \n",
    "        #call function to calculate n day moving average\n",
    "        md(data, n, val_name, f)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [?] n day EMA calculation \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "def ema(data, n, val_name, f):\n",
    "\n",
    "    prices = []\n",
    "\n",
    "    EMA = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if index == 0:\n",
    "            past_ema = row[val_name]\n",
    "            EMA.append(row[val_name])\n",
    "        else:\n",
    "            # Y=[2*X+(N-1)*Y’]/(N+1)\n",
    "            today_ema = (2 * row[val_name] + (n - 1) * past_ema) / (n + 1)\n",
    "            past_ema = today_ema\n",
    "\n",
    "            EMA.append(today_ema)\n",
    "            \n",
    "    colName = 'EMA_'+str(n)\n",
    "    data[colName] = EMA\n",
    "    fileName = savePath + f\n",
    "    data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    n = input('Day you want to calculate?')\n",
    "    n = int(n)\n",
    "    val_name = input('Value you want to calculate?')\n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        \n",
    "        #call function to calculate n day moving average\n",
    "        ema(data, n, val_name, f)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] W&R calculation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "def wnr(data, n, f):\n",
    "\n",
    "    high_prices = []\n",
    "    low_prices = []\n",
    "    WNR = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        high_prices.append(row['high'])\n",
    "        if len(high_prices) == n:\n",
    "            del high_prices[0]\n",
    "        low_prices.append(row['low'])\n",
    "        if len(low_prices) == n:\n",
    "            del low_prices[0]\n",
    "\n",
    "        highest = max(high_prices)\n",
    "        lowest = min(low_prices)\n",
    "\n",
    "        if highest - lowest == 0:\n",
    "            wnr = 0\n",
    "        else:\n",
    "            wnr = (highest - row['close']) / (highest - lowest) * 100\n",
    "        WNR.append(wnr)\n",
    "        \n",
    "    colName = 'WNR_'+str(n)\n",
    "    data[colName] = WNR\n",
    "    fileName = savePath + f\n",
    "    data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "\n",
    "    return WNR\n",
    "\n",
    "def main():\n",
    "    n = input('Day you want to calculate?')\n",
    "    n = int(n)\n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        \n",
    "        #call function to calculate n day moving average\n",
    "        wnr(data, n, f)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [15] bias calculation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "def ma(data, n, val_name):\n",
    "    values = []\n",
    "    MA = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        values.append(row[val_name])\n",
    "        if len(values) == n:\n",
    "            del values[0]\n",
    "\n",
    "        MA.append(np.average(values))\n",
    "\n",
    "    return np.asarray(MA)\n",
    "\n",
    "def bias(data, n, f):\n",
    "\n",
    "    val_name = 'close'\n",
    "    MA = ma(data, n, val_name)\n",
    "    CLOSES = data['close']\n",
    "    BIAS = (np.true_divide((CLOSES - MA), MA)) * (100 / 100)\n",
    "    \n",
    "    colName = 'BIAS_'+str(n)\n",
    "    data[colName] = BIAS\n",
    "    fileName = savePath + f\n",
    "    data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    return BIAS\n",
    "\n",
    "def main():\n",
    "    n = input('Day you want to calculate?')\n",
    "    n = int(n)\n",
    "    for f in fileList:\n",
    "        try:\n",
    "            fileName = loadPath + f\n",
    "            data = pd.read_csv(fileName)\n",
    "\n",
    "            #call function to calculate n day moving average\n",
    "            bias(data, n, f)\n",
    "        except:\n",
    "            print(\"exection on {}\".format(f))\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [8] momentum calculation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "def mtm(data, n, f):\n",
    "\n",
    "    MTM = []\n",
    "    CN = []\n",
    "    for index, row in data.iterrows():\n",
    "        if index < n - 1:\n",
    "            MTM.append(0.)\n",
    "        else:\n",
    "            mtm = row['close'] - CN[index - n]\n",
    "            MTM.append(mtm)\n",
    "        CN.append(row['close'])\n",
    "        \n",
    "    colName = 'MTM_'+str(n)\n",
    "    data[colName] = MTM\n",
    "    fileName = savePath + f\n",
    "    data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    return np.asarray(MTM)\n",
    "\n",
    "def main():\n",
    "    n = input('Day you want to calculate?')\n",
    "    n = int(n) # usually n = 6\n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        \n",
    "        #call function to calculate n day moving average\n",
    "        mtm(data, n, f)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [13] VR calculation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "def vr(data, n, f):\n",
    "    VR = []\n",
    "\n",
    "    AV_volumes, BV_volumes, CV_volumes = [], [], []\n",
    "    for index, row in data.iterrows():\n",
    "\n",
    "        if row['close'] > row['open']:\n",
    "            AV_volumes.append(row['vol'])\n",
    "        elif row['close'] < row['open']:\n",
    "            BV_volumes.append(row['vol'])\n",
    "        else:\n",
    "            CV_volumes.append(row['vol'])\n",
    "\n",
    "        if len(AV_volumes) == n:\n",
    "            del AV_volumes[0]\n",
    "        if len(BV_volumes) == n:\n",
    "            del BV_volumes[0]\n",
    "        if len(CV_volumes) == n:\n",
    "            del CV_volumes[0]\n",
    "\n",
    "        avs = sum(AV_volumes)\n",
    "        bvs = sum(BV_volumes)\n",
    "        cvs = sum(CV_volumes)\n",
    "\n",
    "        if (bvs + (1 / 2) * cvs) != 0:\n",
    "            vr = (avs + (1 / 2) * cvs) / (bvs + (1 / 2) * cvs)\n",
    "        else:\n",
    "            vr = 0\n",
    "\n",
    "        VR.append(vr)\n",
    "        \n",
    "    colName = 'VR_'+str(n)\n",
    "    data[colName] = VR\n",
    "    fileName = savePath + f\n",
    "    data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "\n",
    "    return np.asarray(VR)\n",
    "\n",
    "def main():\n",
    "    n = input('Day you want to calculate?')\n",
    "    n = int(n) # usually n = 26\n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        \n",
    "        #call function to calculate n day moving average\n",
    "        vr(data, n, f)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [11] [12] AR and BR calculation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "def arbr(data, n, f):\n",
    "    import numpy as np\n",
    "\n",
    "    H, L, O, PC = np.array([0]), np.array([0]), np.array([0]), np.array([0])\n",
    "\n",
    "    AR, BR = np.array([0]), np.array([0])\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if index == 0:\n",
    "            last_row = row\n",
    "\n",
    "        else:\n",
    "\n",
    "            h = row['high']\n",
    "            H = np.append(H, [h])\n",
    "            if len(H) == n:\n",
    "                H = np.delete(H, 0)\n",
    "            l = row['low']\n",
    "            L = np.append(L, [l])\n",
    "            if len(L) == n:\n",
    "                L = np.delete(L, 0)\n",
    "            o = row['open']\n",
    "            O = np.append(O, [o])\n",
    "            if len(O) == n:\n",
    "                O = np.delete(O, 0)\n",
    "            pc = last_row['close']\n",
    "            PC = np.append(PC, [pc])\n",
    "            if len(PC) == n:\n",
    "                PC = np.delete(PC, 0)\n",
    "\n",
    "            ar = (np.sum(np.asarray(H) - np.asarray(O)) / sum(np.asarray(O) - np.asarray(L))) * 100\n",
    "            AR = np.append(AR, [ar])\n",
    "            br = (np.sum(np.asarray(H) - np.asarray(PC)) / sum(np.asarray(PC) - np.asarray(L))) * 100\n",
    "            BR = np.append(BR, [br])\n",
    "\n",
    "            last_row = row\n",
    "            \n",
    "    colName1 = 'AR_'+str(n)\n",
    "    colName2 = 'BR_'+str(n)\n",
    "    data[colName1] = AR\n",
    "    data[colName2] = BR\n",
    "    fileName = savePath + f\n",
    "    data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "\n",
    "    return np.asarray(AR), np.asarray(BR)\n",
    "\n",
    "def main():\n",
    "    n = input('Day you want to calculate?')\n",
    "    n = int(n) # usually n = 26\n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        \n",
    "        #call function to calculate n day moving average\n",
    "        arbr(data, n, f)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] [2] stochaistic KDJ\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "def kdj(data, f):\n",
    "\n",
    "    K, D, J = [], [], []\n",
    "    last_k, last_d = None, None\n",
    "    for index, row in data.iterrows():\n",
    "        if last_k is None or last_d is None:\n",
    "            last_k = 50\n",
    "            last_d = 50\n",
    "\n",
    "        c, l, h = row['close'], row['low'], row['high']\n",
    "\n",
    "        if h-l == 0:\n",
    "            rsv = 0\n",
    "        else:\n",
    "            rsv = (c - l) / (h - l) * 100\n",
    "\n",
    "        k = (2 / 3) * last_k + (1 / 3) * rsv\n",
    "        d = (2 / 3) * last_d + (1 / 3) * k\n",
    "        j = 3 * k - 2 * d\n",
    "\n",
    "        K.append(k)\n",
    "        D.append(d)\n",
    "        J.append(j)\n",
    "\n",
    "        last_k, last_d = k, d\n",
    "    \n",
    "    colName1 = 'K'\n",
    "    colName2 = 'D'\n",
    "    colName3 = 'J'\n",
    "    data[colName1] = K\n",
    "    data[colName2] = D\n",
    "    data[colName3] = J\n",
    "    fileName = savePath + f\n",
    "    data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "\n",
    "    return np.asarray(K), np.asarray(D), np.asarray(J)\n",
    "\n",
    "def main():\n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        \n",
    "        #call function to calculate n day moving average\n",
    "        kdj(data, f)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [6] MACD calculation \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "def ema(data, n, val_name):\n",
    "\n",
    "    prices = []\n",
    "\n",
    "    EMA = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if index == 0:\n",
    "            past_ema = row[val_name]\n",
    "            EMA.append(row[val_name])\n",
    "        else:\n",
    "            # Y=[2*X+(N-1)*Y’]/(N+1)\n",
    "            today_ema = (2 * row[val_name] + (n - 1) * past_ema) / (n + 1)\n",
    "            past_ema = today_ema\n",
    "\n",
    "            EMA.append(today_ema)\n",
    "\n",
    "    return np.asarray(EMA)\n",
    "\n",
    "def macd(data, quick_n, slow_n, dem_n, val_name, f):\n",
    "\n",
    "    ema_quick = np.asarray(ema(data, quick_n, val_name))\n",
    "    ema_slow = np.asarray(ema(data, slow_n, val_name))\n",
    "    DIFF = ema_quick - ema_slow\n",
    "    data['DIFF'] = DIFF\n",
    "    DEM = ema(data, dem_n, 'DIFF')\n",
    "    data['DEM'] = DEM\n",
    "    OSC = DIFF - DEM\n",
    "    \n",
    "    data['MACD'] = OSC\n",
    "    fileName = savePath + f\n",
    "    data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def main():\n",
    "    quick_n=12\n",
    "    slow_n=26\n",
    "    dem_n=9\n",
    "    val_name='close'\n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        \n",
    "        #call function to calculate n day moving average\n",
    "        macd(data, quick_n, slow_n, dem_n, val_name, f)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4] CCI calculation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "# fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "fileList = ['002645.SZ.csv', '300697.SZ.csv']\n",
    "\n",
    "\n",
    "# def ma(data, n, val_name):\n",
    "#     values = []\n",
    "#     MA = []\n",
    "\n",
    "#     for index, row in data.iterrows():\n",
    "#         values.append(row[val_name])\n",
    "#         if len(values) == n:\n",
    "#             del values[0]\n",
    "\n",
    "#         MA.append(np.average(values))\n",
    "\n",
    "#     return np.asarray(MA)\n",
    "\n",
    "# def md(data, n, val_name):\n",
    "#     values = []\n",
    "#     MD = []\n",
    "\n",
    "#     for index, row in data.iterrows():\n",
    "#         values.append(row[val_name])\n",
    "#         if len(values) == n:\n",
    "#             del values[0]\n",
    "\n",
    "#         MD.append(np.std(values))\n",
    "    \n",
    "#     return np.asarray(MD)\n",
    "\n",
    "\n",
    "def cci(data, n, f):\n",
    "    \n",
    "    TP = []\n",
    "    SMATP = []\n",
    "    MD = []\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        c, l, h = row['close'], row['low'], row['high']\n",
    "        tp = (1 / 3) * (c + l + h) \n",
    "        TP.append(tp)\n",
    "        if len(TP) == n:\n",
    "            del TP[0]\n",
    "\n",
    "        SMATP.append(np.average(TP))\n",
    "        MD.append(np.std((np.asarray(TP)-np.asarray(SMATP)))\n",
    "    \n",
    "    CCI = (TP - SMATP) * (1 / 0.015 * MD)\n",
    "    \n",
    "    colName = 'CCI_'+str(n)\n",
    "    data[colName] = CCI\n",
    "    fileName = savePath + f\n",
    "    data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "\n",
    "    return np.asarray(CCI)\n",
    "\n",
    "def main():\n",
    "    n = input('Days you want to calculate')\n",
    "    n = int(n)\n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        \n",
    "        #call function to calculate n day moving average\n",
    "        cci(data, n, f)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 2 indicators together and save to one file, JUST EXAMPLE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def ma(data, n, val_name):\n",
    "    values = []\n",
    "    MA = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        values.append(row[val_name])\n",
    "        if len(values) == n:\n",
    "            del values[0]\n",
    "\n",
    "        MA.append(np.average(values))\n",
    "    data['MA_10'] = MA\n",
    "#     fileName = savePath + f\n",
    "#     data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "\n",
    "    return data\n",
    "\n",
    "def md(data, n, val_name, f):\n",
    "    values = []\n",
    "    MD = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        values.append(row[val_name])\n",
    "        if len(values) == n:\n",
    "            del values[0]\n",
    "\n",
    "        MD.append(np.std(values))\n",
    "    data['MD_10'] = MD\n",
    "    fileName = savePath + f\n",
    "    data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    n = input('Day you want to calculate?')\n",
    "    n = int(n)\n",
    "    val_name = input('Value you want to calculate?')\n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        \n",
    "        #call function to calculate n day moving average\n",
    "        md(ma(data, n, val_name), n, val_name, f)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grand truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program the grand truth\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "processedList = []\n",
    "\n",
    "loadPath = '/Users/jenieshen/Study/graduateThesis/Project/data/processed/daily/'\n",
    "savePath = '/Users/jenieshen/Study/graduateThesis/Project/data/processed/ground_truth/'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "# fileList = ['002645.SZ.csv']\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    data = pd.read_csv(fileName)\n",
    "    \n",
    "    idxList = data.index.values.tolist()\n",
    "    gtList = []\n",
    "\n",
    "    for i in idxList:\n",
    "        cls_prc = data['close'].iloc[i]\n",
    "        precls_prc = data['pre_close'].iloc[i]\n",
    "        if cls_prc > precls_prc:\n",
    "            gtList.append(1)\n",
    "        else:\n",
    "            gtList.append(0)\n",
    "    data['up_down'] = gtList\n",
    "    \n",
    "    # save file\n",
    "    fileName = savePath + f\n",
    "    data.to_csv(fileName, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground truth for weekly prediction (added w_up_down) use 5th open price compare with 1st close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program the grand truth\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "processedList = []\n",
    "\n",
    "loadPath = '/Users/jenieshen/Study/graduateThesis/Project/data/processed/Structure/'\n",
    "savePath = '/Users/jenieshen/Study/graduateThesis/Project/data/processed/weekly_labeled/'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "# fileList = ['002645.SZ.csv']\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    data = pd.read_csv(fileName)\n",
    "    \n",
    "    idxList = data.index.values.tolist()\n",
    "    gtList = [0, 0, 0, 0]\n",
    "\n",
    "    for i in idxList[4:]:\n",
    "        op_prc = data['open'].iloc[i]\n",
    "        precls_prc = data['pre_close'].iloc[i-4]\n",
    "        if op_prc > precls_prc:\n",
    "            gtList.append(1)\n",
    "        else:\n",
    "            gtList.append(0)\n",
    "            \n",
    "    try:\n",
    "        data['w_up_down'] = gtList\n",
    "        # save file\n",
    "        fileName = savePath + f\n",
    "        data[4:].to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    except:\n",
    "        print('exception in {}'.format(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground truth for different trading date from 2 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program the grand truth\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "processedList = []\n",
    "\n",
    "date_range = 9  # change savePath and date_range to create different groundtruth\n",
    "\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath' + str(date_range+1) + '/'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "# fileList = ['002645.SZ.csv']\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    data = pd.read_csv(fileName)\n",
    "    \n",
    "    idxList = data.index.values.tolist()\n",
    "    gtList = [0] * date_range\n",
    "\n",
    "    for i in idxList[date_range:]:\n",
    "        op_prc = data['open'].iloc[i]\n",
    "        precls_prc = data['pre_close'].iloc[i-date_range]\n",
    "        if op_prc > precls_prc:\n",
    "            gtList.append(1)\n",
    "        else:\n",
    "            gtList.append(0)\n",
    "            \n",
    "    try:\n",
    "        data['w_up_down'] = gtList\n",
    "        # save file\n",
    "        fileName = savePath + f\n",
    "        data[date_range:].to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    except:\n",
    "        print('exception in {}'.format(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extension \n",
    "<br> All column names: 'ts_code', 'trade_date', 'open', 'high', 'low', 'close', 'pre_close', 'change', 'pct_chg', 'vol', 'amount', 'SMA_10', 'MACD', 'MACD_SIGNAL', 'MACD_HIST', 'CCI_24', 'MTM_10', 'ROC_10', 'RSI_5', 'WNR_9', 'SLOWK', 'SLOWD', 'ADOSC', 'AR_26', 'BR_26', 'VR_26', 'BIAS_20', 'up_down'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maxminscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extension - maxminscaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def cutnull_fillna(org_df):\n",
    "    df = org_df.iloc[33:,:].copy() # Cut rows for calculation, index 0 is corresponding to row 2\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fe_scl(input_sr):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    input_sr = input_sr.values.reshape(-1, 1)\n",
    "    scl_result = scaler.fit_transform(input_sr)\n",
    "    \n",
    "    return scl_result\n",
    "\n",
    "def df_concat(df1, sr, col):\n",
    "    \n",
    "    colName = col+'_maxmin'\n",
    "    df1[colName] = sr\n",
    "    \n",
    "    return df1\n",
    "\n",
    "def main():\n",
    "    processedList = []\n",
    "\n",
    "    loadPath = 'yourloadpath'\n",
    "    savePath = 'yoursavepath'\n",
    "\n",
    "    fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "#     fileList = ['002645.SZ.csv'] # single file test\n",
    "    \n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        data = cutnull_fillna(data)\n",
    "        idxList = data.index.values.tolist()\n",
    "        \n",
    "        # save all column names that should be done minmaxscaler into the list below\n",
    "        colName = ['vol', \n",
    "                   'amount', \n",
    "                   'SMA_10',  \n",
    "                   'RSI_5', \n",
    "                   'WNR_9', \n",
    "                   'SLOWK', \n",
    "                   'SLOWD', \n",
    "                   'ADOSC', \n",
    "                   'AR_26', \n",
    "                   'BR_26', \n",
    "                   'VR_26', \n",
    "                   'BIAS_20']\n",
    "        try:\n",
    "            for c in colName:\n",
    "                result = fe_scl(data[c])\n",
    "                df_concat(data, result, c)\n",
    "        except:\n",
    "            print('Exception on file {}'.format(f))\n",
    "            \n",
    "        fileName = savePath + f\n",
    "        data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "        processedList.append(f)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extension - Polarize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def fe_plr(input_sr):\n",
    "#     # Commented by using existed preprocessing package\n",
    "#     count = 0\n",
    "#     plr_result = []\n",
    "#     input_str = input_sr.values.tolist()\n",
    "    \n",
    "#     for i in input_str:\n",
    "#             try:\n",
    "#                 if i[0] > 0:\n",
    "#                     plr_value = 1\n",
    "#                 else:\n",
    "#                     plr_value = 0\n",
    "\n",
    "#                 plr_result.append(plr_value)\n",
    "#             except:\n",
    "#                 plr_result.append('')\n",
    "#                 print('exception on index {}'.format(count))\n",
    "#             count = count + 1\n",
    "    input_sr = input_sr.values.reshape(-1, 1)\n",
    "    normalizer = preprocessing.Normalizer().fit(input_sr)\n",
    "    plr_result = normalizer.transform(input_sr)\n",
    "    \n",
    "    return plr_result\n",
    "\n",
    "def df_concat(df1, sr, col):\n",
    "    \n",
    "    colName = col+'_plr'\n",
    "    df1[colName] = sr\n",
    "    \n",
    "    return df1\n",
    "\n",
    "def main():\n",
    "    processedList = []\n",
    "\n",
    "    loadPath = 'yourloadpath'\n",
    "    savePath = 'yoursavepath'\n",
    "\n",
    "    fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "#     fileList = ['002645.SZ.csv'] # single file test\n",
    "    \n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        idxList = data.index.values.tolist()\n",
    "        \n",
    "        # save all column names that should be done polarize into the list below\n",
    "        colName = ['MACD', \n",
    "                   'MACD_SIGNAL', \n",
    "                   'MACD_HIST', \n",
    "                   'CCI_24', \n",
    "                   'MTM_10', \n",
    "                   'ROC_10', \n",
    "                   'WNR_9', \n",
    "                   'ADOSC', \n",
    "                   'BIAS_20']\n",
    "        \n",
    "        try:\n",
    "            for c in colName:\n",
    "                result = fe_plr(data[c])\n",
    "                df_concat(data, result, c)\n",
    "        except:\n",
    "            print('Exception on file {}'.format(f))\n",
    "        \n",
    "        fileName = savePath + f\n",
    "        data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "        processedList.append(f)\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program the indices fluctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program the indices fluctuation\n",
    "# Feature extension - normalize\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def fe_flc(input_sr, val_name):\n",
    "    values = []\n",
    "    \n",
    "    for index, row in input_sr.iterrows():\n",
    "        if index == 0:\n",
    "            past_value = row[val_name]\n",
    "            values.append(row[val_name])\n",
    "        else:\n",
    "            # Y=[2*X+(N-1)*Y’]/(N+1)\n",
    "            today_value = row[val_name]\n",
    "            pct_flc = (row[val_name] - past_value) / past_value\n",
    "            past_value = today_value\n",
    "\n",
    "            values.append(pct_flc)\n",
    "        \n",
    "    return values\n",
    "\n",
    "def df_concat(df1, sr, col):\n",
    "    \n",
    "    colName = col+'_flc'\n",
    "    df1[colName] = sr\n",
    "    \n",
    "    return df1\n",
    "\n",
    "def main():\n",
    "    processedList = []\n",
    "\n",
    "    loadPath = 'yourloadpath'\n",
    "    savePath = 'yoursavepath'\n",
    "\n",
    "    fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "#     fileList = ['002645.SZ.csv']\n",
    "\n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        idxList = data.index.values.tolist()\n",
    "\n",
    "        # save all column names that should be done normalization into the list below\n",
    "        colName = ['vol',\n",
    "                   'amount', \n",
    "                   'SMA_10', \n",
    "                   'MTM_10', \n",
    "                   'ROC_10', \n",
    "                   'RSI_5',\n",
    "                   'WNR_9', \n",
    "                   'SLOWK', \n",
    "                   'SLOWD']\n",
    "        try:\n",
    "            for c in colName:\n",
    "                result = fe_flc(data[colName], c)\n",
    "                df_concat(data, result, c)\n",
    "        except:\n",
    "            print('Exception on file {}'.format(f))\n",
    "        \n",
    "        data = data.iloc[1:,:].copy() # Cut first row of df before saving\n",
    "        fileName = savePath + f\n",
    "        data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "        \n",
    "        processedList.append(f)\n",
    "            \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other dataframe modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program the indices fluctuation\n",
    "# Feature extension - normalize\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Move the label column to the end\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "#     fileList = ['002645.SZ.csv']\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    data = pd.read_csv(fileName)\n",
    "    \n",
    "    cols_at_end = ['up_down']\n",
    "    data = data[[c for c in data if c not in cols_at_end] + [c for c in cols_at_end if c in data]]\n",
    "\n",
    "    fileName = savePath + f\n",
    "    data.to_csv(fileName, encoding = 'utf-8', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize is the method before performing PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the result from data exploring, and processing them through PCA, to descope 10 features into 5\n",
    "# Extract 10 effective features from the original dataset and save them\n",
    "\n",
    "def main():\n",
    "    processedList = []\n",
    "\n",
    "    loadPath = 'yourloadpath'\n",
    "    savePath = 'yoursavepath'\n",
    "\n",
    "    fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "#     fileList = ['002645.SZ.csv']\n",
    "    \n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        idxList = data.index.values.tolist()\n",
    "\n",
    "        # save all column names that should be done normalization into the list below\n",
    "        colName = [\n",
    "                     'ts_code',\n",
    "                     'trade_date', \n",
    "                     'SLOWK_maxmin',\n",
    "                     'SLOWK',\n",
    "                     'SLOWD_maxmin',\n",
    "                     'RSI_5_maxmin',\n",
    "                     'SLOWD',\n",
    "                     'RSI_5',\n",
    "                     'SLOWK_flc',\n",
    "                     'WNR_9_maxmin',\n",
    "                     'WNR_9',\n",
    "                     'CCI_24',\n",
    "                     'BIAS_20_maxmin',\n",
    "                     'BIAS_20',\n",
    "                     'ADOSC_maxmin',\n",
    "                     'ADOSC',\n",
    "                     'WNR_9_flc',\n",
    "                     'w_up_down'\n",
    "                  ]\n",
    "        try:\n",
    "            data = data[colName]\n",
    "            fileName = savePath + f\n",
    "            data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "        except:\n",
    "            print('Exception on file {}'.format(f))\n",
    "            \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data for PCA usage, PCA Part goes to data modeling\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def fe_nm(input_sr):\n",
    "#     scl_result = np.empty()\n",
    "    \n",
    "    normalizer = preprocessing.Normalizer().fit(input_sr)\n",
    "    scl_result = normalizer.transform(input_sr)\n",
    "#     scl_result = preprocessing.normalize(input_sr, norm='l2') # commented to use normalizer\n",
    "    \n",
    "    return scl_result\n",
    "\n",
    "def df_rename(data, col):\n",
    "    l = len(col)\n",
    "    \n",
    "    for i in range(l):\n",
    "        colnew = col[i] + '_nm'\n",
    "        data_rename = data.rename(columns={i:colnew}, inplace=True)\n",
    "    \n",
    "    return data_rename\n",
    "\n",
    "def main():\n",
    "    processedList = []\n",
    "\n",
    "    loadPath = 'yourloadpath'\n",
    "    savePath = 'yoursavepath'\n",
    "\n",
    "    fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "#     fileList = ['002645.SZ.csv']\n",
    "\n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        idxList = data.index.values.tolist()\n",
    "        \n",
    "        # fill inf and null\n",
    "        data = data.replace([np.inf, -np.inf], 0)\n",
    "        data.fillna(0, inplace=True)\n",
    "        \n",
    "        # save all column names that should be done normalization into the list below\n",
    "        colName = [  # columns for normalizing only\n",
    "                             'SLOWK_maxmin',\n",
    "                             'SLOWK',\n",
    "                             'SLOWD_maxmin',\n",
    "                             'RSI_5_maxmin',\n",
    "                             'SLOWD',\n",
    "                             'RSI_5',\n",
    "                             'SLOWK_flc',\n",
    "                             'WNR_9_maxmin',\n",
    "                             'WNR_9',\n",
    "                             'CCI_24',\n",
    "                             'BIAS_20_maxmin',\n",
    "                             'BIAS_20',\n",
    "                             'ADOSC_maxmin',\n",
    "                             'ADOSC',\n",
    "                             'WNR_9_flc',\n",
    "                  ]\n",
    "        \n",
    "        try:\n",
    "            result = fe_nm(data[colName])\n",
    "\n",
    "            data_nm = pd.DataFrame.from_records(result)\n",
    "\n",
    "            data_aft = pd.concat([data, data_nm], axis=1)\n",
    "\n",
    "            df_rename(data_aft, colName)\n",
    "\n",
    "            colNameFull = [  # all the columns\n",
    "                             'ts_code',\n",
    "                             'trade_date', \n",
    "                             'SLOWK_maxmin',\n",
    "                             'SLOWK',\n",
    "                             'SLOWD_maxmin',\n",
    "                             'RSI_5_maxmin',\n",
    "                             'SLOWD',\n",
    "                             'RSI_5',\n",
    "                             'SLOWK_flc',\n",
    "                             'WNR_9_maxmin',\n",
    "                             'WNR_9',\n",
    "                             'CCI_24',\n",
    "                             'BIAS_20_maxmin',\n",
    "                             'BIAS_20',\n",
    "                             'ADOSC_maxmin',\n",
    "                             'ADOSC',\n",
    "                             'WNR_9_flc',\n",
    "                             'w_up_down'\n",
    "                          ]\n",
    "\n",
    "            data_aft = data_aft[colNameFull]\n",
    "\n",
    "            fileName = savePath + f\n",
    "            data_aft.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "        \n",
    "        except:\n",
    "            print('Exception on file {}'.format(f))\n",
    "            \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extension - normalize original code (a template, copy paste it for modification usage)\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def fe_nm(input_sr):\n",
    "#     scl_result = np.empty()\n",
    "    \n",
    "    normalizer = preprocessing.Normalizer().fit(input_sr)\n",
    "    scl_result = normalizer.transform(input_sr)\n",
    "#     scl_result = preprocessing.normalize(input_sr, norm='l2') # commented to use normalizer\n",
    "    \n",
    "    return scl_result\n",
    "\n",
    "def df_rename(data, col):\n",
    "    l = len(col)\n",
    "    \n",
    "    for i in range(l):\n",
    "        colnew = col[i] + '_nm'\n",
    "        data_rename = data.rename(columns={i:colnew}, inplace=True)\n",
    "    \n",
    "    return data_rename\n",
    "\n",
    "def main():\n",
    "    processedList = []\n",
    "\n",
    "    loadPath = 'yourloadpath'\n",
    "    savePath = 'yoursavepath'\n",
    "\n",
    "    # fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "\n",
    "    fileList = ['002645.SZ.csv']\n",
    "\n",
    "    for f in fileList:\n",
    "        fileName = loadPath + f\n",
    "        data = pd.read_csv(fileName)\n",
    "        idxList = data.index.values.tolist()\n",
    "\n",
    "        # save all column names that should be done normalization into the list below\n",
    "        colName = ['change', 'pct_chg']\n",
    "\n",
    "        result = fe_nm(data[colName])\n",
    "\n",
    "        data_nm = pd.DataFrame.from_records(result)\n",
    "\n",
    "        data_aft = pd.concat([data, data_nm], axis=1)\n",
    "\n",
    "        df_rename(data_aft, colName)\n",
    "\n",
    "        fileName = savePath + f\n",
    "        data_aft.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "            \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

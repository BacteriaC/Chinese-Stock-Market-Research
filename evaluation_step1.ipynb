{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation step1, date range affectiveness, date range = 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste test section\n",
    "# minmaxscaler and fillna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tempfile import TemporaryFile\n",
    "import random\n",
    "\n",
    "processedList = []\n",
    "errorList = []\n",
    "# outfile = TemporaryFile()\n",
    "\n",
    "date_range = 0  # change savePath and date_range to create different groundtruth\n",
    "\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "fileList = random.sample(fileList, 100)  # random select \n",
    "# fileList = ['002645.SZ.csv', '002114.SZ.csv', '603032.SH.csv']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "a_s = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_r = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_gs = np.zeros([1, 56]) # calculated according to X shape\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    data = pd.read_csv(fileName)\n",
    "    data = data.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "#     #debug\n",
    "#     fileName = savePath + f\n",
    "#     data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    y = data['up_down'].values.tolist()\n",
    "    X = data.iloc[:,2:58].copy() # To avoid the case where changing X also changes data, only excluded the ts code and trading date\n",
    "    X.fillna(0, inplace=True)\n",
    "    X = X.values\n",
    "    \n",
    "    y0 = np.zeros([1,1])\n",
    "    y = np.append(y, y0)  # add a 0 at the end of label and pop all label up one day, use today data to predict tomorrow result\n",
    "    y = np.delete(y, (0), axis=0) # delete first row to ensure the lenth is correct\n",
    "    \n",
    "    X = X[:-1, :]  # delete the last row of X because the last row of indices are correspoinding to y0\n",
    "    y = y[:-1]  # delete the last row of y because the last row of label is y0\n",
    "    \n",
    "    try:\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        estimator = SVR(kernel=\"linear\")\n",
    "        selector = RFECV(estimator, step=1, cv=5)\n",
    "        selector = selector.fit(X, y)\n",
    "        \n",
    "        condition = selector.support_\n",
    "\n",
    "        if len(condition)%56 == 0:\n",
    "            a_s = np.vstack((a_s, selector.support_))\n",
    "            a_r = np.vstack((a_r, selector.ranking_))\n",
    "            \n",
    "            a_gs = np.vstack((a_gs, selector.grid_scores_))\n",
    "\n",
    "            \n",
    "#             np.save(savePath+'a_s_weekly.npy', a_s)\n",
    "#             np.save(savePath+'a_r_weekly.npy', a_r)\n",
    "            \n",
    "            processedList.append(f)\n",
    "        else:\n",
    "            errorList.append(f)\n",
    "    except:\n",
    "        errorList.append(f)\n",
    "\n",
    "# feature ranking array\n",
    "\n",
    "a_s = np.delete(a_s, (0), axis=0) # delete first row\n",
    "a_r = np.delete(a_r, (0), axis=0) # delete first row\n",
    "a_gs = np.delete(a_gs, (0), axis=0) # delete first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[2:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxnameList = data.columns[2:58].tolist()\n",
    "idxsptList = np.sum(a_s, axis=0).tolist()\n",
    "idxrkList = np.sum(a_r, axis=0).tolist()\n",
    "idxgsList = np.mean(a_gs, axis=0).tolist()\n",
    "a_gs_mean = np.mean(a_gs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE = pd.DataFrame(\n",
    "    {'Name': idxnameList,\n",
    "     'Support': idxsptList,\n",
    "     'Rank': idxrkList,\n",
    "     'Grid_Score': idxgsList\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Rank')\n",
    "temp = df_RFE.sort_values('Rank')['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Support')\n",
    "temp = df_RFE.sort_values('Support', ascending = False)['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(a_gs_mean) + 1), a_gs_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = savePath + 'RFE_' + str(date_range + 1) + 'days_prediction.csv'\n",
    "df_RFE.to_csv(fileName, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation step1, date range affectiveness, date range = 2 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste test section\n",
    "# minmaxscaler and fillna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tempfile import TemporaryFile\n",
    "import random\n",
    "\n",
    "processedList = []\n",
    "errorList = []\n",
    "# outfile = TemporaryFile()\n",
    "\n",
    "date_range = 1  # change savePath and date_range to create different groundtruth\n",
    "\n",
    "loadPath = 'yourloadpath'+ str(date_range+1) + '/'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "fileList = random.sample(fileList, 100)  # random select \n",
    "# fileList = ['002645.SZ.csv', '002114.SZ.csv', '603032.SH.csv']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "a_s = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_r = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_gs = np.zeros([1, 56]) # calculated according to X shape\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    data = pd.read_csv(fileName)\n",
    "    data = data.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "#     #debug\n",
    "#     fileName = savePath + f\n",
    "#     data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    y = data['w_up_down'].values.tolist()\n",
    "    X = data.iloc[:,2:58].copy() # To avoid the case where changing X also changes data, only excluded the ts code and trading date\n",
    "    X.fillna(0, inplace=True)\n",
    "    X = X.values\n",
    "    \n",
    "    y0 = np.zeros([1,1])\n",
    "    y = np.append(y, y0)  # add a 0 at the end of label and pop all label up one day, use today data to predict tomorrow result\n",
    "    y = np.delete(y, (0), axis=0) # delete first row to ensure the lenth is correct\n",
    "    \n",
    "    X = X[:-1, :]  # delete the last row of X because the last row of indices are correspoinding to y0\n",
    "    y = y[:-1]  # delete the last row of y because the last row of label is y0\n",
    "    \n",
    "    try:\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        estimator = SVR(kernel=\"linear\")\n",
    "        selector = RFECV(estimator, step=1, cv=5)\n",
    "        selector = selector.fit(X, y)\n",
    "        \n",
    "        condition = selector.support_\n",
    "\n",
    "        if len(condition)%56 == 0:\n",
    "            a_s = np.vstack((a_s, selector.support_))\n",
    "            a_r = np.vstack((a_r, selector.ranking_))\n",
    "            \n",
    "            a_gs = np.vstack((a_gs, selector.grid_scores_))\n",
    "\n",
    "            \n",
    "#             np.save(savePath+'a_s_weekly.npy', a_s)\n",
    "#             np.save(savePath+'a_r_weekly.npy', a_r)\n",
    "            \n",
    "            processedList.append(f)\n",
    "        else:\n",
    "            errorList.append(f)\n",
    "    except:\n",
    "        errorList.append(f)\n",
    "\n",
    "# feature ranking array\n",
    "\n",
    "a_s = np.delete(a_s, (0), axis=0) # delete first row\n",
    "a_r = np.delete(a_r, (0), axis=0) # delete first row\n",
    "a_gs = np.delete(a_gs, (0), axis=0) # delete first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[2:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxnameList = data.columns[2:58].tolist()\n",
    "idxsptList = np.sum(a_s, axis=0).tolist()\n",
    "idxrkList = np.sum(a_r, axis=0).tolist()\n",
    "idxgsList = np.mean(a_gs, axis=0).tolist()\n",
    "a_gs_mean = np.mean(a_gs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE = pd.DataFrame(\n",
    "    {'Name': idxnameList,\n",
    "     'Support': idxsptList,\n",
    "     'Rank': idxrkList,\n",
    "     'Grid_Score': idxgsList\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Rank')\n",
    "temp = df_RFE.sort_values('Rank')['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Support')\n",
    "temp = df_RFE.sort_values('Support', ascending = False)['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(a_gs_mean) + 1), a_gs_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = savePath + 'RFE_' + str(date_range + 1) + 'days_prediction.csv'\n",
    "df_RFE.to_csv(fileName, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation step1, date range affectiveness, date range = 3 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste test section\n",
    "# minmaxscaler and fillna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tempfile import TemporaryFile\n",
    "import random\n",
    "\n",
    "processedList = []\n",
    "errorList = []\n",
    "# outfile = TemporaryFile()\n",
    "\n",
    "date_range = 2  # change savePath and date_range to create different groundtruth\n",
    "\n",
    "\n",
    "loadPath = 'yourloadpath'+ str(date_range+1) + '/'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "fileList = random.sample(fileList, 100)  # random select \n",
    "# fileList = ['002645.SZ.csv', '002114.SZ.csv', '603032.SH.csv']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "a_s = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_r = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_gs = np.zeros([1, 56]) # calculated according to X shape\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    data = pd.read_csv(fileName)\n",
    "    data = data.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "#     #debug\n",
    "#     fileName = savePath + f\n",
    "#     data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    y = data['w_up_down'].values.tolist()\n",
    "    X = data.iloc[:,2:58].copy() # To avoid the case where changing X also changes data, only excluded the ts code and trading date\n",
    "    X.fillna(0, inplace=True)\n",
    "    X = X.values\n",
    "    \n",
    "    y0 = np.zeros([1,1])\n",
    "    y = np.append(y, y0)  # add a 0 at the end of label and pop all label up one day, use today data to predict tomorrow result\n",
    "    y = np.delete(y, (0), axis=0) # delete first row to ensure the lenth is correct\n",
    "    \n",
    "    X = X[:-1, :]  # delete the last row of X because the last row of indices are correspoinding to y0\n",
    "    y = y[:-1]  # delete the last row of y because the last row of label is y0\n",
    "    \n",
    "    try:\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        estimator = SVR(kernel=\"linear\")\n",
    "        selector = RFECV(estimator, step=1, cv=5)\n",
    "        selector = selector.fit(X, y)\n",
    "        \n",
    "        condition = selector.support_\n",
    "\n",
    "        if len(condition)%56 == 0:\n",
    "            a_s = np.vstack((a_s, selector.support_))\n",
    "            a_r = np.vstack((a_r, selector.ranking_))\n",
    "            \n",
    "            a_gs = np.vstack((a_gs, selector.grid_scores_))\n",
    "\n",
    "            \n",
    "#             np.save(savePath+'a_s_weekly.npy', a_s)\n",
    "#             np.save(savePath+'a_r_weekly.npy', a_r)\n",
    "            \n",
    "            processedList.append(f)\n",
    "        else:\n",
    "            errorList.append(f)\n",
    "    except:\n",
    "        errorList.append(f)\n",
    "\n",
    "# feature ranking array\n",
    "\n",
    "a_s = np.delete(a_s, (0), axis=0) # delete first row\n",
    "a_r = np.delete(a_r, (0), axis=0) # delete first row\n",
    "a_gs = np.delete(a_gs, (0), axis=0) # delete first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[2:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxnameList = data.columns[2:58].tolist()\n",
    "idxsptList = np.sum(a_s, axis=0).tolist()\n",
    "idxrkList = np.sum(a_r, axis=0).tolist()\n",
    "idxgsList = np.mean(a_gs, axis=0).tolist()\n",
    "a_gs_mean = np.mean(a_gs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE = pd.DataFrame(\n",
    "    {'Name': idxnameList,\n",
    "     'Support': idxsptList,\n",
    "     'Rank': idxrkList,\n",
    "     'Grid_Score': idxgsList\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Rank')\n",
    "temp = df_RFE.sort_values('Rank')['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Support')\n",
    "temp = df_RFE.sort_values('Support', ascending = False)['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(a_gs_mean) + 1), a_gs_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = savePath + 'RFE_' + str(date_range + 1) + 'days_prediction.csv'\n",
    "df_RFE.to_csv(fileName, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation step1, date range affectiveness, date range = 4 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste test section\n",
    "# minmaxscaler and fillna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tempfile import TemporaryFile\n",
    "import random\n",
    "\n",
    "processedList = []\n",
    "errorList = []\n",
    "# outfile = TemporaryFile()\n",
    "\n",
    "date_range = 3  # change savePath and date_range to create different groundtruth\n",
    "\n",
    "loadPath = 'yourloadpath'+ str(date_range+1) + '/'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "fileList = random.sample(fileList, 100)  # random select \n",
    "# fileList = ['002645.SZ.csv', '002114.SZ.csv', '603032.SH.csv']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "a_s = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_r = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_gs = np.zeros([1, 56]) # calculated according to X shape\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    data = pd.read_csv(fileName)\n",
    "    data = data.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "#     #debug\n",
    "#     fileName = savePath + f\n",
    "#     data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    y = data['w_up_down'].values.tolist()\n",
    "    X = data.iloc[:,2:58].copy() # To avoid the case where changing X also changes data, only excluded the ts code and trading date\n",
    "    X.fillna(0, inplace=True)\n",
    "    X = X.values\n",
    "    \n",
    "    y0 = np.zeros([1,1])\n",
    "    y = np.append(y, y0)  # add a 0 at the end of label and pop all label up one day, use today data to predict tomorrow result\n",
    "    y = np.delete(y, (0), axis=0) # delete first row to ensure the lenth is correct\n",
    "    \n",
    "    X = X[:-1, :]  # delete the last row of X because the last row of indices are correspoinding to y0\n",
    "    y = y[:-1]  # delete the last row of y because the last row of label is y0\n",
    "    \n",
    "    try:\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        estimator = SVR(kernel=\"linear\")\n",
    "        selector = RFECV(estimator, step=1, cv=5)\n",
    "        selector = selector.fit(X, y)\n",
    "        \n",
    "        condition = selector.support_\n",
    "\n",
    "        if len(condition)%56 == 0:\n",
    "            a_s = np.vstack((a_s, selector.support_))\n",
    "            a_r = np.vstack((a_r, selector.ranking_))\n",
    "            \n",
    "            a_gs = np.vstack((a_gs, selector.grid_scores_))\n",
    "\n",
    "            \n",
    "#             np.save(savePath+'a_s_weekly.npy', a_s)\n",
    "#             np.save(savePath+'a_r_weekly.npy', a_r)\n",
    "            \n",
    "            processedList.append(f)\n",
    "        else:\n",
    "            errorList.append(f)\n",
    "    except:\n",
    "        errorList.append(f)\n",
    "\n",
    "# feature ranking array\n",
    "\n",
    "a_s = np.delete(a_s, (0), axis=0) # delete first row\n",
    "a_r = np.delete(a_r, (0), axis=0) # delete first row\n",
    "a_gs = np.delete(a_gs, (0), axis=0) # delete first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[2:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxnameList = data.columns[2:58].tolist()\n",
    "idxsptList = np.sum(a_s, axis=0).tolist()\n",
    "idxrkList = np.sum(a_r, axis=0).tolist()\n",
    "idxgsList = np.mean(a_gs, axis=0).tolist()\n",
    "a_gs_mean = np.mean(a_gs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE = pd.DataFrame(\n",
    "    {'Name': idxnameList,\n",
    "     'Support': idxsptList,\n",
    "     'Rank': idxrkList,\n",
    "     'Grid_Score': idxgsList\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Rank')\n",
    "temp = df_RFE.sort_values('Rank')['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Support')\n",
    "temp = df_RFE.sort_values('Support', ascending = False)['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(a_gs_mean) + 1), a_gs_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = savePath + 'RFE_' + str(date_range + 1) + 'days_prediction.csv'\n",
    "df_RFE.to_csv(fileName, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation step1, date range affectiveness, date range = 5 days (weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste test section\n",
    "# minmaxscaler and fillna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tempfile import TemporaryFile\n",
    "import random\n",
    "\n",
    "processedList = []\n",
    "errorList = []\n",
    "# outfile = TemporaryFile()\n",
    "\n",
    "date_range = 4  # change savePath and date_range to create different groundtruth\n",
    "\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "fileList = random.sample(fileList, 100)  # random select \n",
    "# fileList = ['002645.SZ.csv', '002114.SZ.csv', '603032.SH.csv']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "a_s = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_r = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_gs = np.zeros([1, 56]) # calculated according to X shape\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    data = pd.read_csv(fileName)\n",
    "    data = data.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "#     #debug\n",
    "#     fileName = savePath + f\n",
    "#     data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    y = data['w_up_down'].values.tolist()\n",
    "    X = data.iloc[:,2:58].copy() # To avoid the case where changing X also changes data, only excluded the ts code and trading date\n",
    "    X.fillna(0, inplace=True)\n",
    "    X = X.values\n",
    "    \n",
    "    y0 = np.zeros([1,1])\n",
    "    y = np.append(y, y0)  # add a 0 at the end of label and pop all label up one day, use today data to predict tomorrow result\n",
    "    y = np.delete(y, (0), axis=0) # delete first row to ensure the lenth is correct\n",
    "    \n",
    "    X = X[:-1, :]  # delete the last row of X because the last row of indices are correspoinding to y0\n",
    "    y = y[:-1]  # delete the last row of y because the last row of label is y0\n",
    "    \n",
    "    try:\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        estimator = SVR(kernel=\"linear\")\n",
    "        selector = RFECV(estimator, step=1, cv=5)\n",
    "        selector = selector.fit(X, y)\n",
    "        \n",
    "        condition = selector.support_\n",
    "\n",
    "        if len(condition)%56 == 0:\n",
    "            a_s = np.vstack((a_s, selector.support_))\n",
    "            a_r = np.vstack((a_r, selector.ranking_))\n",
    "            \n",
    "            a_gs = np.vstack((a_gs, selector.grid_scores_))\n",
    "\n",
    "            \n",
    "#             np.save(savePath+'a_s_weekly.npy', a_s)\n",
    "#             np.save(savePath+'a_r_weekly.npy', a_r)\n",
    "            \n",
    "            processedList.append(f)\n",
    "        else:\n",
    "            errorList.append(f)\n",
    "    except:\n",
    "        errorList.append(f)\n",
    "\n",
    "# feature ranking array\n",
    "\n",
    "a_s = np.delete(a_s, (0), axis=0) # delete first row\n",
    "a_r = np.delete(a_r, (0), axis=0) # delete first row\n",
    "a_gs = np.delete(a_gs, (0), axis=0) # delete first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[2:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxnameList = data.columns[2:58].tolist()\n",
    "idxsptList = np.sum(a_s, axis=0).tolist()\n",
    "idxrkList = np.sum(a_r, axis=0).tolist()\n",
    "idxgsList = np.mean(a_gs, axis=0).tolist()\n",
    "a_gs_mean = np.mean(a_gs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE = pd.DataFrame(\n",
    "    {'Name': idxnameList,\n",
    "     'Support': idxsptList,\n",
    "     'Rank': idxrkList,\n",
    "     'Grid_Score': idxgsList\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Rank')\n",
    "temp = df_RFE.sort_values('Rank')['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Support')\n",
    "temp = df_RFE.sort_values('Support', ascending = False)['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(a_gs_mean) + 1), a_gs_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = savePath + 'RFE_' + str(date_range + 1) + 'days_prediction.csv'\n",
    "df_RFE.to_csv(fileName, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation step1, date range affectiveness, date range = 6 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste test section\n",
    "# minmaxscaler and fillna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tempfile import TemporaryFile\n",
    "import random\n",
    "\n",
    "processedList = []\n",
    "errorList = []\n",
    "# outfile = TemporaryFile()\n",
    "\n",
    "date_range = 5  # change savePath and date_range to create different groundtruth\n",
    "\n",
    "loadPath = 'yourloadpath' + str(date_range+1) + '/'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "fileList = random.sample(fileList, 100)  # random select \n",
    "# fileList = ['002645.SZ.csv', '002114.SZ.csv', '603032.SH.csv']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "a_s = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_r = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_gs = np.zeros([1, 56]) # calculated according to X shape\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    data = pd.read_csv(fileName)\n",
    "    data = data.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "#     #debug\n",
    "#     fileName = savePath + f\n",
    "#     data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    y = data['w_up_down'].values.tolist()\n",
    "    X = data.iloc[:,2:58].copy() # To avoid the case where changing X also changes data, only excluded the ts code and trading date\n",
    "    X.fillna(0, inplace=True)\n",
    "    X = X.values\n",
    "    \n",
    "    y0 = np.zeros([1,1])\n",
    "    y = np.append(y, y0)  # add a 0 at the end of label and pop all label up one day, use today data to predict tomorrow result\n",
    "    y = np.delete(y, (0), axis=0) # delete first row to ensure the lenth is correct\n",
    "    \n",
    "    X = X[:-1, :]  # delete the last row of X because the last row of indices are correspoinding to y0\n",
    "    y = y[:-1]  # delete the last row of y because the last row of label is y0\n",
    "    \n",
    "    try:\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        estimator = SVR(kernel=\"linear\")\n",
    "        selector = RFECV(estimator, step=1, cv=5)\n",
    "        selector = selector.fit(X, y)\n",
    "        \n",
    "        condition = selector.support_\n",
    "\n",
    "        if len(condition)%56 == 0:\n",
    "            a_s = np.vstack((a_s, selector.support_))\n",
    "            a_r = np.vstack((a_r, selector.ranking_))\n",
    "            \n",
    "            a_gs = np.vstack((a_gs, selector.grid_scores_))\n",
    "\n",
    "            \n",
    "#             np.save(savePath+'a_s_weekly.npy', a_s)\n",
    "#             np.save(savePath+'a_r_weekly.npy', a_r)\n",
    "            \n",
    "            processedList.append(f)\n",
    "        else:\n",
    "            errorList.append(f)\n",
    "    except:\n",
    "        errorList.append(f)\n",
    "\n",
    "# feature ranking array\n",
    "\n",
    "a_s = np.delete(a_s, (0), axis=0) # delete first row\n",
    "a_r = np.delete(a_r, (0), axis=0) # delete first row\n",
    "a_gs = np.delete(a_gs, (0), axis=0) # delete first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[2:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxnameList = data.columns[2:58].tolist()\n",
    "idxsptList = np.sum(a_s, axis=0).tolist()\n",
    "idxrkList = np.sum(a_r, axis=0).tolist()\n",
    "idxgsList = np.mean(a_gs, axis=0).tolist()\n",
    "a_gs_mean = np.mean(a_gs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE = pd.DataFrame(\n",
    "    {'Name': idxnameList,\n",
    "     'Support': idxsptList,\n",
    "     'Rank': idxrkList,\n",
    "     'Grid_Score': idxgsList\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Rank')\n",
    "temp = df_RFE.sort_values('Rank')['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Support')\n",
    "temp = df_RFE.sort_values('Support', ascending = False)['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(a_gs_mean) + 1), a_gs_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = savePath + 'RFE_' + str(date_range + 1) + 'days_prediction.csv'\n",
    "df_RFE.to_csv(fileName, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation step1, date range affectiveness, date range = 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste test section\n",
    "# minmaxscaler and fillna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tempfile import TemporaryFile\n",
    "import random\n",
    "\n",
    "processedList = []\n",
    "errorList = []\n",
    "# outfile = TemporaryFile()\n",
    "\n",
    "date_range = 6  # change savePath and date_range to create different groundtruth\n",
    "\n",
    "loadPath = 'yourloadpath' + str(date_range+1) + '/'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "fileList = random.sample(fileList, 100)  # random select \n",
    "# fileList = ['002645.SZ.csv', '002114.SZ.csv', '603032.SH.csv']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "a_s = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_r = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_gs = np.zeros([1, 56]) # calculated according to X shape\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    data = pd.read_csv(fileName)\n",
    "    data = data.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "#     #debug\n",
    "#     fileName = savePath + f\n",
    "#     data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    y = data['w_up_down'].values.tolist()\n",
    "    X = data.iloc[:,2:58].copy() # To avoid the case where changing X also changes data, only excluded the ts code and trading date\n",
    "    X.fillna(0, inplace=True)\n",
    "    X = X.values\n",
    "    \n",
    "    y0 = np.zeros([1,1])\n",
    "    y = np.append(y, y0)  # add a 0 at the end of label and pop all label up one day, use today data to predict tomorrow result\n",
    "    y = np.delete(y, (0), axis=0) # delete first row to ensure the lenth is correct\n",
    "    \n",
    "    X = X[:-1, :]  # delete the last row of X because the last row of indices are correspoinding to y0\n",
    "    y = y[:-1]  # delete the last row of y because the last row of label is y0\n",
    "    \n",
    "    try:\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        estimator = SVR(kernel=\"linear\")\n",
    "        selector = RFECV(estimator, step=1, cv=5)\n",
    "        selector = selector.fit(X, y)\n",
    "        \n",
    "        condition = selector.support_\n",
    "\n",
    "        if len(condition)%56 == 0:\n",
    "            a_s = np.vstack((a_s, selector.support_))\n",
    "            a_r = np.vstack((a_r, selector.ranking_))\n",
    "            \n",
    "            a_gs = np.vstack((a_gs, selector.grid_scores_))\n",
    "\n",
    "            \n",
    "#             np.save(savePath+'a_s_weekly.npy', a_s)\n",
    "#             np.save(savePath+'a_r_weekly.npy', a_r)\n",
    "            \n",
    "            processedList.append(f)\n",
    "        else:\n",
    "            errorList.append(f)\n",
    "    except:\n",
    "        errorList.append(f)\n",
    "\n",
    "# feature ranking array\n",
    "\n",
    "a_s = np.delete(a_s, (0), axis=0) # delete first row\n",
    "a_r = np.delete(a_r, (0), axis=0) # delete first row\n",
    "a_gs = np.delete(a_gs, (0), axis=0) # delete first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[2:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxnameList = data.columns[2:58].tolist()\n",
    "idxsptList = np.sum(a_s, axis=0).tolist()\n",
    "idxrkList = np.sum(a_r, axis=0).tolist()\n",
    "idxgsList = np.mean(a_gs, axis=0).tolist()\n",
    "a_gs_mean = np.mean(a_gs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE = pd.DataFrame(\n",
    "    {'Name': idxnameList,\n",
    "     'Support': idxsptList,\n",
    "     'Rank': idxrkList,\n",
    "     'Grid_Score': idxgsList\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Rank')\n",
    "temp = df_RFE.sort_values('Rank')['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Support')\n",
    "temp = df_RFE.sort_values('Support', ascending = False)['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(a_gs_mean) + 1), a_gs_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = savePath + 'RFE_' + str(date_range + 1) + 'days_prediction.csv'\n",
    "df_RFE.to_csv(fileName, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation step1, date range affectiveness, date range = 8 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste test section\n",
    "# minmaxscaler and fillna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tempfile import TemporaryFile\n",
    "import random\n",
    "\n",
    "processedList = []\n",
    "errorList = []\n",
    "# outfile = TemporaryFile()\n",
    "\n",
    "date_range = 7  # change savePath and date_range to create different groundtruth\n",
    "\n",
    "loadPath = 'yourloadpath' + str(date_range+1) + '/'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "fileList = random.sample(fileList, 100)  # random select \n",
    "# fileList = ['002645.SZ.csv', '002114.SZ.csv', '603032.SH.csv']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "a_s = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_r = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_gs = np.zeros([1, 56]) # calculated according to X shape\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    data = pd.read_csv(fileName)\n",
    "    data = data.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "#     #debug\n",
    "#     fileName = savePath + f\n",
    "#     data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    y = data['w_up_down'].values.tolist()\n",
    "    X = data.iloc[:,2:58].copy() # To avoid the case where changing X also changes data, only excluded the ts code and trading date\n",
    "    X.fillna(0, inplace=True)\n",
    "    X = X.values\n",
    "    \n",
    "    y0 = np.zeros([1,1])\n",
    "    y = np.append(y, y0)  # add a 0 at the end of label and pop all label up one day, use today data to predict tomorrow result\n",
    "    y = np.delete(y, (0), axis=0) # delete first row to ensure the lenth is correct\n",
    "    \n",
    "    X = X[:-1, :]  # delete the last row of X because the last row of indices are correspoinding to y0\n",
    "    y = y[:-1]  # delete the last row of y because the last row of label is y0\n",
    "    \n",
    "    try:\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        estimator = SVR(kernel=\"linear\")\n",
    "        selector = RFECV(estimator, step=1, cv=5)\n",
    "        selector = selector.fit(X, y)\n",
    "        \n",
    "        condition = selector.support_\n",
    "\n",
    "        if len(condition)%56 == 0:\n",
    "            a_s = np.vstack((a_s, selector.support_))\n",
    "            a_r = np.vstack((a_r, selector.ranking_))\n",
    "            \n",
    "            a_gs = np.vstack((a_gs, selector.grid_scores_))\n",
    "\n",
    "            \n",
    "#             np.save(savePath+'a_s_weekly.npy', a_s)\n",
    "#             np.save(savePath+'a_r_weekly.npy', a_r)\n",
    "            \n",
    "            processedList.append(f)\n",
    "        else:\n",
    "            errorList.append(f)\n",
    "    except:\n",
    "        errorList.append(f)\n",
    "\n",
    "# feature ranking array\n",
    "\n",
    "a_s = np.delete(a_s, (0), axis=0) # delete first row\n",
    "a_r = np.delete(a_r, (0), axis=0) # delete first row\n",
    "a_gs = np.delete(a_gs, (0), axis=0) # delete first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[2:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxnameList = data.columns[2:58].tolist()\n",
    "idxsptList = np.sum(a_s, axis=0).tolist()\n",
    "idxrkList = np.sum(a_r, axis=0).tolist()\n",
    "idxgsList = np.mean(a_gs, axis=0).tolist()\n",
    "a_gs_mean = np.mean(a_gs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE = pd.DataFrame(\n",
    "    {'Name': idxnameList,\n",
    "     'Support': idxsptList,\n",
    "     'Rank': idxrkList,\n",
    "     'Grid_Score': idxgsList\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Rank')\n",
    "temp = df_RFE.sort_values('Rank')['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Support')\n",
    "temp = df_RFE.sort_values('Support', ascending = False)['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(a_gs_mean) + 1), a_gs_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = savePath + 'RFE_' + str(date_range + 1) + 'days_prediction.csv'\n",
    "df_RFE.to_csv(fileName, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation step1, date range affectiveness, date range = 9 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste test section\n",
    "# minmaxscaler and fillna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tempfile import TemporaryFile\n",
    "import random\n",
    "\n",
    "processedList = []\n",
    "errorList = []\n",
    "# outfile = TemporaryFile()\n",
    "\n",
    "date_range = 8  # change savePath and date_range to create different groundtruth\n",
    "\n",
    "loadPath = 'yourloadpath' + str(date_range+1) + '/'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "fileList = random.sample(fileList, 100)  # random select \n",
    "# fileList = ['002645.SZ.csv', '002114.SZ.csv', '603032.SH.csv']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "a_s = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_r = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_gs = np.zeros([1, 56]) # calculated according to X shape\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    data = pd.read_csv(fileName)\n",
    "    data = data.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "#     #debug\n",
    "#     fileName = savePath + f\n",
    "#     data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    y = data['w_up_down'].values.tolist()\n",
    "    X = data.iloc[:,2:58].copy() # To avoid the case where changing X also changes data, only excluded the ts code and trading date\n",
    "    X.fillna(0, inplace=True)\n",
    "    X = X.values\n",
    "    \n",
    "    y0 = np.zeros([1,1])\n",
    "    y = np.append(y, y0)  # add a 0 at the end of label and pop all label up one day, use today data to predict tomorrow result\n",
    "    y = np.delete(y, (0), axis=0) # delete first row to ensure the lenth is correct\n",
    "    \n",
    "    X = X[:-1, :]  # delete the last row of X because the last row of indices are correspoinding to y0\n",
    "    y = y[:-1]  # delete the last row of y because the last row of label is y0\n",
    "    \n",
    "    try:\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        estimator = SVR(kernel=\"linear\")\n",
    "        selector = RFECV(estimator, step=1, cv=5)\n",
    "        selector = selector.fit(X, y)\n",
    "        \n",
    "        condition = selector.support_\n",
    "\n",
    "        if len(condition)%56 == 0:\n",
    "            a_s = np.vstack((a_s, selector.support_))\n",
    "            a_r = np.vstack((a_r, selector.ranking_))\n",
    "            \n",
    "            a_gs = np.vstack((a_gs, selector.grid_scores_))\n",
    "\n",
    "            \n",
    "#             np.save(savePath+'a_s_weekly.npy', a_s)\n",
    "#             np.save(savePath+'a_r_weekly.npy', a_r)\n",
    "            \n",
    "            processedList.append(f)\n",
    "        else:\n",
    "            errorList.append(f)\n",
    "    except:\n",
    "        errorList.append(f)\n",
    "\n",
    "# feature ranking array\n",
    "\n",
    "a_s = np.delete(a_s, (0), axis=0) # delete first row\n",
    "a_r = np.delete(a_r, (0), axis=0) # delete first row\n",
    "a_gs = np.delete(a_gs, (0), axis=0) # delete first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[2:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxnameList = data.columns[2:58].tolist()\n",
    "idxsptList = np.sum(a_s, axis=0).tolist()\n",
    "idxrkList = np.sum(a_r, axis=0).tolist()\n",
    "idxgsList = np.mean(a_gs, axis=0).tolist()\n",
    "a_gs_mean = np.mean(a_gs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE = pd.DataFrame(\n",
    "    {'Name': idxnameList,\n",
    "     'Support': idxsptList,\n",
    "     'Rank': idxrkList,\n",
    "     'Grid_Score': idxgsList\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Rank')\n",
    "temp = df_RFE.sort_values('Rank')['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Support')\n",
    "temp = df_RFE.sort_values('Support', ascending = False)['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(a_gs_mean) + 1), a_gs_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = savePath + 'RFE_' + str(date_range + 1) + 'days_prediction.csv'\n",
    "df_RFE.to_csv(fileName, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation step1, date range affectiveness, date range = 10 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste test section\n",
    "# minmaxscaler and fillna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tempfile import TemporaryFile\n",
    "import random\n",
    "\n",
    "processedList = []\n",
    "errorList = []\n",
    "# outfile = TemporaryFile()\n",
    "\n",
    "date_range = 9  # change savePath and date_range to create different groundtruth\n",
    "\n",
    "loadPath = 'yourloadpath' + str(date_range+1) + '/'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "fileList = random.sample(fileList, 100)  # random select \n",
    "# fileList = ['002645.SZ.csv', '002114.SZ.csv', '603032.SH.csv']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "a_s = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_r = np.zeros([1, 56]) # calculated according to X shape\n",
    "a_gs = np.zeros([1, 56]) # calculated according to X shape\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    data = pd.read_csv(fileName)\n",
    "    data = data.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "#     #debug\n",
    "#     fileName = savePath + f\n",
    "#     data.to_csv(fileName, encoding = 'utf-8', index = False)\n",
    "    \n",
    "    y = data['w_up_down'].values.tolist()\n",
    "    X = data.iloc[:,2:58].copy() # To avoid the case where changing X also changes data, only excluded the ts code and trading date\n",
    "    X.fillna(0, inplace=True)\n",
    "    X = X.values\n",
    "    \n",
    "    y0 = np.zeros([1,1])\n",
    "    y = np.append(y, y0)  # add a 0 at the end of label and pop all label up one day, use today data to predict tomorrow result\n",
    "    y = np.delete(y, (0), axis=0) # delete first row to ensure the lenth is correct\n",
    "    \n",
    "    X = X[:-1, :]  # delete the last row of X because the last row of indices are correspoinding to y0\n",
    "    y = y[:-1]  # delete the last row of y because the last row of label is y0\n",
    "    \n",
    "    try:\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        estimator = SVR(kernel=\"linear\")\n",
    "        selector = RFECV(estimator, step=1, cv=5)\n",
    "        selector = selector.fit(X, y)\n",
    "        \n",
    "        condition = selector.support_\n",
    "\n",
    "        if len(condition)%56 == 0:\n",
    "            a_s = np.vstack((a_s, selector.support_))\n",
    "            a_r = np.vstack((a_r, selector.ranking_))\n",
    "            \n",
    "            a_gs = np.vstack((a_gs, selector.grid_scores_))\n",
    "\n",
    "            \n",
    "#             np.save(savePath+'a_s_weekly.npy', a_s)\n",
    "#             np.save(savePath+'a_r_weekly.npy', a_r)\n",
    "            \n",
    "            processedList.append(f)\n",
    "        else:\n",
    "            errorList.append(f)\n",
    "    except:\n",
    "        errorList.append(f)\n",
    "\n",
    "# feature ranking array\n",
    "\n",
    "a_s = np.delete(a_s, (0), axis=0) # delete first row\n",
    "a_r = np.delete(a_r, (0), axis=0) # delete first row\n",
    "a_gs = np.delete(a_gs, (0), axis=0) # delete first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[2:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxnameList = data.columns[2:58].tolist()\n",
    "idxsptList = np.sum(a_s, axis=0).tolist()\n",
    "idxrkList = np.sum(a_r, axis=0).tolist()\n",
    "idxgsList = np.mean(a_gs, axis=0).tolist()\n",
    "a_gs_mean = np.mean(a_gs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE = pd.DataFrame(\n",
    "    {'Name': idxnameList,\n",
    "     'Support': idxsptList,\n",
    "     'Rank': idxrkList,\n",
    "     'Grid_Score': idxgsList\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Rank')\n",
    "temp = df_RFE.sort_values('Rank')['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE.sort_values('Support')\n",
    "temp = df_RFE.sort_values('Support', ascending = False)['Name'].tolist()\n",
    "temp[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(a_gs_mean) + 1), a_gs_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = savePath + 'RFE_' + str(date_range + 1) + 'days_prediction.csv'\n",
    "df_RFE.to_csv(fileName, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test section from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste test section\n",
    "# minmaxscaler and fillna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from time import sleep\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tempfile import TemporaryFile\n",
    "import random\n",
    "\n",
    "loadPath = 'yourloadpath'\n",
    "savePath = 'yoursavepath'\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "fileList = [f for f in listdir(loadPath) if isfile(join(loadPath, f))]\n",
    "# fileList = ['RFE_7days_prediction.csv']\n",
    "\n",
    "for f in fileList:\n",
    "    fileName = loadPath + f\n",
    "    try:\n",
    "        data = pd.read_csv(fileName)\n",
    "        col = f[4:9]\n",
    "        new_df[col] = data['Grid_Score']\n",
    "    except:\n",
    "        print(f)\n",
    "        \n",
    "fileName = savePath + 'RFE_curve.csv'\n",
    "new_df.to_csv(fileName, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.tools.set_credentials_file(username='username', api_key='apikey')\n",
    "\n",
    "# Create random data with numpy\n",
    "import numpy as np\n",
    "\n",
    "feature_num = new_df.index.values.tolist()\n",
    "\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x = feature_num,\n",
    "    y = new_df['1days'],\n",
    "    name = '1 day',\n",
    "    line = dict(\n",
    "        color = ('rgb(220, 220, 220)'),\n",
    "        width = 2,\n",
    "        dash = 'dash' # dash options include 'dash', 'dot', and 'dashdot'\n",
    "    )\n",
    ")\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = feature_num,\n",
    "    y = new_df['2days'],\n",
    "    name = '2 days',\n",
    "    line = dict(\n",
    "        color = ('rgb(205, 12, 24)'),\n",
    "        width = 4)\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x = feature_num,\n",
    "    y = new_df['3days'],\n",
    "    name = '3 days',\n",
    "    line = dict(\n",
    "        color = ('rgb(220, 220, 220)'),\n",
    "        width = 2,\n",
    "        dash = 'dash' # dash options include 'dash', 'dot', and 'dashdot'\n",
    "    )\n",
    ")\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "    x = feature_num,\n",
    "    y = new_df['4days'],\n",
    "    name = '4 days',\n",
    "    line = dict(\n",
    "        color = ('rgb(220, 220, 220)'),\n",
    "        width = 2,\n",
    "        dash = 'dash' # dash options include 'dash', 'dot', and 'dashdot'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "trace4 = go.Scatter(\n",
    "    x = feature_num,\n",
    "    y = new_df['5days'],\n",
    "    name = '5 days',\n",
    "    line = dict(\n",
    "        color = ('rgb(255, 191, 0)'),\n",
    "        width = 2)\n",
    ")\n",
    "\n",
    "trace5 = go.Scatter(\n",
    "    x = feature_num,\n",
    "    y = new_df['6days'],\n",
    "    name = '6 days',\n",
    "    line = dict(\n",
    "        color = ('rgb(220, 220, 220)'),\n",
    "        width = 2,\n",
    "        dash = 'dash' # dash options include 'dash', 'dot', and 'dashdot'\n",
    "    )\n",
    ")\n",
    "\n",
    "trace6 = go.Scatter(\n",
    "    x = feature_num,\n",
    "    y = new_df['7days'],\n",
    "    name = '7 days',\n",
    "    line = dict(\n",
    "        color = ('rgb(220, 220, 220)'),\n",
    "        width = 2,\n",
    "        dash = 'dash' # dash options include 'dash', 'dot', and 'dashdot'\n",
    "    )\n",
    ")\n",
    "\n",
    "trace7 = go.Scatter(\n",
    "    x = feature_num,\n",
    "    y = new_df['8days'],\n",
    "    name = '8 days',\n",
    "    line = dict(\n",
    "        color = ('rgb(220, 220, 220)'),\n",
    "        width = 2,\n",
    "        dash = 'dash' # dash options include 'dash', 'dot', and 'dashdot'\n",
    "    )\n",
    ")\n",
    "\n",
    "trace8 = go.Scatter(\n",
    "    x = feature_num,\n",
    "    y = new_df['9days'],\n",
    "    name = '9 days',\n",
    "    line = dict(\n",
    "        color = ('rgb(220, 220, 220)'),\n",
    "        width = 2,\n",
    "        dash = 'dash' # dash options include 'dash', 'dot', and 'dashdot'\n",
    "    )\n",
    ")\n",
    "\n",
    "trace9 = go.Scatter(\n",
    "    x = feature_num,\n",
    "    y = new_df['10day'],\n",
    "    name = '10 days',\n",
    "    line = dict(\n",
    "        color = ('rgb(205, 12, 24)'),\n",
    "        width = 2\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace0, trace1, trace2, trace3, trace4, trace5, trace6, trace7, trace8, trace9]\n",
    "\n",
    "layout = dict(title = 'How Term Lengths Affect RFE',\n",
    "              xaxis = dict(title = 'Number of features selected'),\n",
    "              yaxis = dict(title = 'Cross validation score (nb of correct classifications)'),\n",
    "              )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='RFE Evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
